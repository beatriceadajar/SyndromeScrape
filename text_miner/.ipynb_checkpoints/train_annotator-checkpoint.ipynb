{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plac, random, spacy\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = [\n",
    "    ('Who is Shaka Khan?', {\n",
    "        'entities': [(7, 17, 'PERSON')]\n",
    "    }),\n",
    "    ('I like London and Berlin.', {\n",
    "        'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]\n",
    "    })\n",
    "    ('The number reached 744 in Cagayan Valley.', {\n",
    "        'entities': [(4, 10, 'CAS')]\n",
    "    }),\n",
    "    ISABELA, Philippines – The rainy season has just started.\n",
    "    The municipality of Luna in Isabela province in the northern Philippines already declared state of calamity after their health office recorded 54 cases of dengue in just the month of June.\n",
    "    Dr Claire Francisco, Luna’s health officer, said on Tuesday, June 30, the number of cases reported for the month is significantly higher compared to the numbers reported in the same month in previous years.\n",
    "    Although there is no case of death from dengue yet, the increase in the reported cases of the disease prompted the local government unit to declare a state of calamity to be able to release funds for the purchase of medical equipment.\n",
    "    In April, the Department of Health (DOH) reported 6.49% increase of dengue cases in the country, citing 19,946 cases in the first quarter of 2015.\n",
    "    The number reached 744 in Cagayan Valley, while Calabarzon had the highest with 3,778 and the Autonomous Region of Muslim Mindanao (ARMM) had the lowest with 312.\n",
    "    The health department is expecting the number of dengue cases to peak in the months of July and August.\",\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@plac.annotations(\n",
    "    model=(\"Model name. Defaults to blank 'en' model.\", \"option\", \"m\", str),\n",
    "    output_dir=(\"Optional output directory\", \"option\", \"o\", Path),\n",
    "    n_iter=(\"Number of training iterations\", \"option\", \"n\", int))\n",
    "def main(model=None, output_dir=None, n_iter=100):\n",
    "    \"\"\"Load the model, set up the pipeline, and train the entity recognizer.\"\"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank('en')  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe('ner')\n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                nlp.update(\n",
    "                    [text],  # batch of texts\n",
    "                    [annotations],  # batch of annotations\n",
    "                    drop=0.5,  # dropout - make it harder to memorise data\n",
    "                    sgd=optimizer,  # callable to update weights\n",
    "                    losses=losses)\n",
    "            print(losses)\n",
    "\n",
    "    # test the trained model\n",
    "    for text, _ in TRAIN_DATA:\n",
    "        doc = nlp(text)\n",
    "        print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "        print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
    "\n",
    "    # save model to output directory\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "\n",
    "        # test the saved model\n",
    "        print(\"Loading from\", output_dir)\n",
    "        nlp2 = spacy.load(output_dir)\n",
    "        for text, _ in TRAIN_DATA:\n",
    "            doc = nlp2(text)\n",
    "            print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "            print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "{'ner': 10.733839458060174}\n",
      "{'ner': 13.417759239673615}\n",
      "{'ner': 8.453623229922414}\n",
      "{'ner': 13.166155847221345}\n",
      "{'ner': 13.099092297328752}\n",
      "{'ner': 10.86783561847405}\n",
      "{'ner': 10.920729713703395}\n",
      "{'ner': 7.651947411417189}\n",
      "{'ner': 6.199139598361398}\n",
      "{'ner': 10.666118910074948}\n",
      "{'ner': 6.009605101296758}\n",
      "{'ner': 6.436598177224457}\n",
      "{'ner': 5.752864415620399}\n",
      "{'ner': 5.963281960464576}\n",
      "{'ner': 3.331284738939247}\n",
      "{'ner': 3.8369747508163776}\n",
      "{'ner': 2.192544459068151}\n",
      "{'ner': 2.4059482158870074}\n",
      "{'ner': 5.3737736658402}\n",
      "{'ner': 1.9955138574639362}\n",
      "{'ner': 1.9997916377277383}\n",
      "{'ner': 3.866743385619974}\n",
      "{'ner': 1.226710903059622e-06}\n",
      "{'ner': 3.586977959934833e-08}\n",
      "{'ner': 8.425989190214598e-09}\n",
      "{'ner': 1.854983806610145}\n",
      "{'ner': 0.0066525815629165375}\n",
      "{'ner': 6.242173822849805e-07}\n",
      "{'ner': 4.776081213082764e-05}\n",
      "{'ner': 1.0749665838507797e-05}\n",
      "{'ner': 1.9691376686299829}\n",
      "{'ner': 0.05439449723717505}\n",
      "{'ner': 7.498639216318706e-13}\n",
      "{'ner': 1.161928365923896e-07}\n",
      "{'ner': 4.0192610896098435e-05}\n",
      "{'ner': 6.359341112898661e-09}\n",
      "{'ner': 1.7389316815720049e-16}\n",
      "{'ner': 4.391402513789966e-07}\n",
      "{'ner': 1.5893282439641344e-13}\n",
      "{'ner': 3.96698238780099e-10}\n",
      "{'ner': 9.955548232564982e-14}\n",
      "{'ner': 0.00588973688852823}\n",
      "{'ner': 1.511273380819692e-14}\n",
      "{'ner': 1.4184684753418146}\n",
      "{'ner': 3.0208169090372386e-08}\n",
      "{'ner': 3.6108331890472504e-13}\n",
      "{'ner': 1.2466032511452783e-17}\n",
      "{'ner': 5.669138107287358e-13}\n",
      "{'ner': 3.250943697651857e-15}\n",
      "{'ner': 7.638291516786099e-19}\n",
      "{'ner': 2.966754758634636e-13}\n",
      "{'ner': 1.4296867078038223e-15}\n",
      "{'ner': 0.00035518279487118526}\n",
      "{'ner': 2.143115018812675e-09}\n",
      "{'ner': 4.6707442228322854e-11}\n",
      "{'ner': 2.0}\n",
      "{'ner': 5.306135062419522e-06}\n",
      "{'ner': 0.04431306581025485}\n",
      "{'ner': 6.227065470581521e-09}\n",
      "{'ner': 5.856065473940828e-19}\n",
      "{'ner': 8.472994522890076e-06}\n",
      "{'ner': 1.4392718792225847e-11}\n",
      "{'ner': 2.147108233807245e-12}\n",
      "{'ner': 3.308170642458306e-11}\n",
      "{'ner': 4.4654364307539876e-20}\n",
      "{'ner': 4.142674511744083e-12}\n",
      "{'ner': 3.2215571878106e-10}\n",
      "{'ner': 1.162637751642322e-11}\n",
      "{'ner': 3.166895678271958e-16}\n",
      "{'ner': 9.227893003965469e-10}\n",
      "{'ner': 0.10634556412698469}\n",
      "{'ner': 1.891804106826372e-09}\n",
      "{'ner': 5.536777553189832e-12}\n",
      "{'ner': 9.845252789202653e-16}\n",
      "{'ner': 4.319184695547108e-14}\n",
      "{'ner': 2.2446168917440027e-22}\n",
      "{'ner': 1.239054319494631e-19}\n",
      "{'ner': 1.5480758973230552e-06}\n",
      "{'ner': 1.9103982747541943e-11}\n",
      "{'ner': 2.4496807473301875e-21}\n",
      "{'ner': 4.6838527620537406e-14}\n",
      "{'ner': 2.577571947706212e-19}\n",
      "{'ner': 3.647350760083464e-18}\n",
      "{'ner': 1.0929507696186023e-24}\n",
      "{'ner': 4.858349120361574e-17}\n",
      "{'ner': 2.1999180538715393e-24}\n",
      "{'ner': 1.160335515933848e-23}\n",
      "{'ner': 9.782620207903192e-12}\n",
      "{'ner': 0.05604556983822909}\n",
      "{'ner': 1.838937520980835}\n",
      "{'ner': 2.058503797420625e-09}\n",
      "{'ner': 6.997410642722964e-23}\n",
      "{'ner': 2.411550088373049e-23}\n",
      "{'ner': 5.0073617087096355e-33}\n",
      "{'ner': 8.507796715872106e-19}\n",
      "{'ner': 6.140742477929036e-27}\n",
      "{'ner': 4.82002494823701e-25}\n",
      "{'ner': 5.5422121407821656e-21}\n",
      "{'ner': 2.7140115189581795e-17}\n",
      "{'ner': 1.1520209555320864e-06}\n",
      "Entities [('Shaka Khan', 'PERSON')]\n",
      "Tokens [('Who', '', 2), ('is', '', 2), ('Shaka', 'PERSON', 3), ('Khan', 'PERSON', 1), ('?', '', 2)]\n",
      "Entities [('London', 'LOC'), ('Berlin', 'LOC')]\n",
      "Tokens [('I', '', 2), ('like', '', 2), ('London', 'LOC', 3), ('and', '', 2), ('Berlin', 'LOC', 3), ('.', '', 2)]\n"
     ]
    }
   ],
   "source": [
    "main()\n",
    "    # Expected output:\n",
    "    # Entities [('Shaka Khan', 'PERSON')]\n",
    "    # Tokens [('Who', '', 2), ('is', '', 2), ('Shaka', 'PERSON', 3),\n",
    "    # ('Khan', 'PERSON', 1), ('?', '', 2)]\n",
    "    # Entities [('London', 'LOC'), ('Berlin', 'LOC')]\n",
    "    # Tokens [('I', '', 2), ('like', '', 2), ('London', 'LOC', 3),\n",
    "    # ('and', '', 2), ('Berlin', 'LOC', 3), ('.', '', 2)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
